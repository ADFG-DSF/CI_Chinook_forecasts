---
title: "Kenai late run 2024 forecast"
author: "Nick DeCovich"
date: "2023-11-06"
output:
  html_document: default
  pdf_document: default
  word_document: default
---
```{r setup, include=FALSE, warning=FALSE}
#Note to Nick. TO me it makes sense to lump all of this together as it is all prep for the analysis which can use common options (Warning = FALSE being a big one.)
knitr::opts_chunk$set(echo = TRUE) #Use these defaults when you want to echo more than you don't.
knitr::opts_chunk$set(warning = FALSE) #Mostly the warnings can/should be left out of the output but I generally run it with them first (by commenting out this line)

rm(list = ls())

devtools::install_github("ADFG-DSF/preseason")
library(preseason)
library(tidyverse)

#Read in Kenai late brood table
brood <- read.csv(".\\KenaiLate2024.csv") #you can make the reference relative so your analysis is portable

#prep data for analysis
dat5 <- prep_brood(brood, 5:5)
dat6 <- prep_brood(brood, 5:6)
dat7 <- prep_brood(brood, 5:7)
```


## Age 5 models

```{r age 5 models}
#Moving average model
## hindcast predictions
dat5$ma5_pred <- pred_ma(dat5$ln, yrs = 5)[, "median"]

#univariate ARIMA
forecast::tsdisplay(dat5$ln, )
forecast::auto.arima(dat5$ln) # This is a random walk model (the most naive forecast out there)
ARIMA5_diff <- arima(dat5$ln, order=c(0,1,0))
summary(ARIMA5_diff)
## hindcast predictions
temp5U <- pred_arima(ARIMA5_diff, x = dat5$ln)
dat5$ARIMA_pred <- exp(temp5U[1,])

#exponential smoothing
ets5 <- forecast::ets(dat5$ln)
## hindcast predictions
dat5$es_pred <- pred_es(dat5$ln)

#compare models
(comp_age5 <- comp_models(dat5, comp_age = 5, years = 5, metric = c("md", "mad", "mape")))
```

Here is an example where carefully examining the past predictions can influence the model selection process. Notice that comp models picks the ARIMA difference model as the best predictor, which is equivalent to a random walk. There is nothing wrong with that even if it has low predictive ability (the prediction is last years value). But a close look at the model comparison plot above shows that exponential smoothing has done better the last several years but did poorly 4 and 5 years ago when the population dropped precipitously. We can verify that by looking at the MAD for the past 3 years... which would suggest exponential smoothing as a better model. In what follows I stuck with model selection using a 5-year MAD but wanted to illustrate how to use these figures to think about the best performing models.

```{r age 5 3 year MAD}
#compare models
## Notice most of the difference comes from 4 and 5 years ago when the population was in serious decline.
##exponential smoothing better recently
comp_models(dat5, comp_age = 5, years = 3)
```

## Age 5 forecast table
```{r age 5 predictions}
#Moving average model
#tail(dat5)
forecast5_ma5 <- exp(mean(dat5$ln[29:33]))

#univariate ARIMA
forecast5_2024 <- forecast5_ARIMA <- exp(predict(ARIMA5_diff, n.ahead = 1)$pred)

#exponential smoothing
forecast5_es <- exp(predict(ets5, h = 1)[["mean"]][1])

#merge 2024 forecast estimate for each model with MAD table
named_df <- function(...){
    names <- as.list(substitute(list(...)))[-1L]
    result <- list(...)
    list(names, result) %>% as.data.frame()
    data.frame(name = as.character(names),
               forecast = round(as.numeric(result), 0)) %>%
      mutate(mod = gsub(".*_(.*)", "\\1", name))
}

comp_age5[[2]] %>%
  mutate(mod = gsub("(.*)_.*", "\\1", type)) %>%
  right_join(named_df(forecast5_ma5, forecast5_ARIMA, forecast5_es), by = "mod") %>%
  select(mod, forecast, md, mad, mape)
```

## Age 6 models
```{r age 6 models}
#Moving average
## hindcast predictions
dat6$ma5_pred <- pred_ma(dat6$age6_ln, yrs = 5)[, "median"]

#univariate ARIMA
forecast::tsdisplay(dat6$age6_ln)
forecast::auto.arima(dat6$age6_ln) # Suggests a random walk
ARIMA6_diff <- arima(dat6$age6_ln, order=c(0,1,0))
ARIMA6_diff
forecast::tsdisplay(residuals(ARIMA6_diff)) #information free
# hindcast predictions
temp_ARIMA6 <- pred_arima(ARIMA6_diff, x = dat6$age6_ln) #more informative names
dat6$ARIMA_pred <- exp(temp_ARIMA6[1,])

#exponential smoothing
ets6 <- forecast::ets(dat6$age6_ln)
# hindcast  predictions
dat6$es_pred <- pred_es(dat6$age6_ln)

#sibling model
ggplot2::ggplot(dat6, ggplot2::aes(x = age5_ln, y = age6_ln)) + #this relationship looks pretty good. Shame not to use.
  ggplot2::geom_point()
sib6 <- lm(age6_ln ~ age5_ln, data = dat6)
summary(sib6) #model significant
par(mfrow = c(2,2)); plot(sib6); par(mfrow = c(1,1)) #residuals not terrible
forecast::tsdisplay(residuals(sib6)) #but appear to contain some additional information
forecast::auto.arima(sib6$model$age6_ln, xreg = sib6$model$age5_ln) #suggests we should difference the data first.
sib6_diff <- arima(sib6$model$age6_ln, order=c(0,1,0), xreg = sib6$model$age5_ln, method = "ML")
sib6_diff
forecast::tsdisplay(residuals(sib6_diff)) #better
## hindcast predictions
dat6$sibling_pred <- exp(pred_arima(sib6_diff, x = sib6$model$age6_ln, xreg = sib6$model$age5_ln)[1,])

#Ricker
plot(dat6$S, dat6$lnRS) #not an obvious relationship
rick6 <- lm(lnRS ~ S, data = dat6)
summary(rick6) #Note the model is not significant
par(mfrow = c(2,2)); plot(rick6); par(mfrow = c(1,1)) #also poor residuals
dat6[19, ] #Note high leverage residual is the largest value of S
#Elected not to consider the Ricker model.

#compare models
(comp_age6 <- comp_models(dat6, comp_age = 6, years = 5, metric = c("md", "mad", "mape")))
```

## Age 6 forecast table
```{r age 6 predictions}
#moving average model
#tail(dat6)
forecast6_ma5 <- exp(mean(dat6$age6_ln[28:32]))

#univariate ARIMA
forecast6_ARIMA <- exp(predict(ARIMA6_diff, n.ahead = 1)$pred)

#ets
forecast6_es <- exp(predict(ets6, h = 1)[["mean"]][1])

#sibling
#tail(brood, 10)
forecast6_2024 <- forecast6_sibling <- exp(predict(sib6_diff, 1, newxreg = log(5214))[[1]])


comp_age6[[2]] %>%
  mutate(mod = gsub("(.*)_.*", "\\1", type)) %>%
  right_join(named_df(forecast6_ma5, forecast6_ARIMA, forecast6_es, forecast6_sibling), by = "mod") %>%
  select(mod, forecast, md, mad, mape)
```
## Age 7 models

```{r age 7 models}
#Moving average
## hindcast predictions
dat7$ma5_pred <- pred_ma(dat7$age7_ln, yrs = 5)[, "median"]

#univariate ARIMA
forecast::tsdisplay(dat7$age7_ln)
forecast::auto.arima(dat7$age7_ln) # Random walk again
ARIMA7_diff <- arima(dat7$age7_ln, order=c(0,1,0))
summary(ARIMA7_diff)
tempU7 <- pred_arima(ARIMA7_diff, x = dat7$age7_ln)
## hindcast predictions
dat7$ARIMA_pred <- exp(tempU7[1,])

#exponential smoothing
ets7 <- forecast::ets(dat7$age7_ln)
## hindcast predictions
dat7$es_pred <- pred_es(dat7$age7_ln)

#sibling model
ggplot2::ggplot(dat7, ggplot2::aes(x = age6_ln, y = age7_ln)) + ggplot2::geom_point()
sib7 <- lm(age7_ln ~ age6_ln, data = dat7)
summary(sib7)
par(mfrow = c(2,2)); plot(sib7); par(mfrow = c(1,1))
forecast::tsdisplay(residuals(sib7))
## hindcast predictions
temp7 <- pred_lm(sib7)
dat7$sibling_pred <- exp(temp7[1,])

#Ricker
plot(dat7$S, dat7$lnRS)
rick7 <- lm(lnRS ~ S, data = dat7)
summary(rick7) #model insignificant
#elected not to use the Ricker model

#compare models
(comp_age7 <- comp_models(dat7, comp_age = 7, years = 5, metric = c("md", "mad", "mape")))
```

## Age 7 forecast table
```{r age 7 predictions}
#moving average model
#tail(dat7)
forecast7_2024 <- forecast7_ma5 <- exp(mean(dat7$age7_ln[27:31]))

#ARIMA
forecast7_ARIMA <- exp(predict(ARIMA7_diff, n.ahead = 1)$pred)

#ets
forecast7_es <- exp(predict(ets7, h = 1)[["mean"]][1])

#sibling
#tail(brood,10)
pred_sib7 <- predict(sib7, newdata = data.frame(age6_ln = log(9322)), se.fit = TRUE)
forecast7_sibling <- exp(pred_sib7$fit)

comp_age7[[2]] %>%
  mutate(mod = gsub("(.*)_.*", "\\1", type)) %>%
  right_join(named_df(forecast7_ma5, forecast7_ARIMA, forecast7_es, forecast7_sibling), by = "mod") %>%
  select(mod, forecast, md, mad, mape)
```

## 2024 Forecast & Prediction Interval
```{r PI calculations}
################################# Calculate prediction intervals ##################################################
#2024 forecast
forecast_2024 <- forecast5_2024[1] + forecast6_2024[1] + forecast7_2024

#Dataframe keypunched from Tony's memo.
#I think this methods is a touch better be it retains variability associated with the model selection process.
#admittedly the selection process has changed, but there is also no guarantee we would choose the same models in past years. 
#Historic age4-6 forecast and actual
dat <- 
  data.frame(
    forecast = c(33613, 21508, 21746, 22707, 18406, 16004, 13630),
    actual = c(30734, 18364, 13360, 12226, 12794, 14078, 14537)
  )

#forecasts bias high, worst at small run sizes
ggplot2::ggplot(dat, ggplot2::aes(x = actual, y = forecast)) +
  ggplot2::geom_point() +
  ggplot2::geom_smooth(method = "lm", se = TRUE) +
  ggplot2::geom_abline(slope = 1)

#2024 Forecast
forecast_2024

#Prediction Interval
dat$resid <- log(dat$forecast) - log(dat$actual)
s <- sqrt(sum(dat$resid^2)/dim(dat)[1])
t <- qt(.90, df = dim(dat)[1] - 1)
exp(log(forecast_2024) + s * c(-t , t))
```

